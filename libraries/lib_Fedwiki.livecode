script "lib_Fedwiki"
--> MetaData
-
name: lib_Fedwiki
type: library
version: 1.7
copyright: David Bovill
licence:  GPLv3
deps: externals
externals:  mergJSONEncode

/*
This library is designed to contain general handlers for manipulating fedwiki data
In particular for constructing and deconstructing fedwiki json.

We should spit out a new model for page-json on the server "model_Fedwiki" or "model_PageJSON"

See also:

- lib_PageArray
- model_PageArray
*/

--> Working on
-
command fedwiki_UpdatePageItem itemText, itemID, pageSlug, wikiDomain
   put pageArray_Fetch (wikiDomain) into pageArray
   pageArray_SetItemText pageArray, itemID, itemText
   pageArray_Store wikiDomain, pageSlug, pageArray
   return pageArray
end fedwiki_UpdatePageItem

function fedwiki_FetchCreationDate wikiDomain, pSlug
   put pageArray_Fetch (wikiDomain, pSlug) into pageArray
   put pageArray_GetCreationDate (pageArray) into createdDate
   return createdDate
end fedwiki_FetchCreationDate

function fedwiki_FetchFirstCreatedSlugArray wikiDomain
   -- here we check each page and item of the journal (slow)
   put fedwiki_ListSitemapSlugs (wikiDomain) into pSlugs
   sort pSlugs
   --
   put the milliseconds into creationDate
   repeat for each line pSlug in pSlugs
      put fedwiki_ExtractFirstAuthorDate (wikiDomain, pSlug) into mSeconds
      if mSeconds is empty then
         next repeat -- page does not exits for some reason even though it is in the sitemap?
      else if mSeconds < creationDate then
         put mSeconds into creationDate
         put creationDate into creationSlugArray ["creationDate"]
         put pSlug into creationSlugArray ["slug"]
      end if
   end repeat
   return creationSlugArray
end fedwiki_FetchFirstCreatedSlugArray

function fedwiki_FetchSiteCreationDate wikiDomain
   -- here we check each page and item of the journal (slow)
   put fedwiki_ListSitemapSlugs (wikiDomain) into pSlugs
   sort pSlugs
   put the milliseconds into creationDate
   repeat for each line pSlug in pSlugs
      put fedwiki_ExtractFirstAuthorDate (wikiDomain, pSlug) into mSeconds
      if mSeconds is empty then
         next repeat -- page does not exits for some reason even though it is in the sitemap?
      else if mSeconds < creationDate then
         put mSeconds into creationDate
      end if
   end repeat
   return creationDate
end fedwiki_FetchSiteCreationDate

function fedwiki_ExtractFirstAuthorDate wikiDomain, pSlug
   put pageArray_Fetch (wikiDomain, pSlug) into pageArray
   put pageArray_ExtractFirstAuthorDate (pageArray, wikiDomain) into mSeconds
   return mSeconds
end fedwiki_ExtractFirstAuthorDate

function fedwiki_FetchCitePageJSON wikiDomain
   -- used by "atopia_CreateFederationSitePage"
   put merge ("http://[[wikiDomain]]/view/welcome-visitors") into lineUpURL
   put fedwiki_ConstructFlagDropJson (lineUpURL) into someJSON
   fedwiki_PostJSON someJSON, "http://home.c2.com:4010/cite"
   put the result into pageJSON
   return pageJSON
end fedwiki_FetchCitePageJSON

function fedwiki_ConstructFlagDropJson lineUpURL
   set the itemdelimiter to slash
   put item 1 to 3 of lineUpURL into wikiDomain
   get merge ("{'text':'','html':'<meta http-equiv=\'Content-Type\' content=\'text/html;charset=UTF-8\'><img src=\'http://[[wikiDomain]]/favicon.png\' height=\'32px\' class=\'favicon\'>','url':'[[lineUpURL]]'}")
   replace "'" with quote in it
   return it
end fedwiki_ConstructFlagDropJson


--> Fedwiki | Return
-
command fedwiki_ExitAndReturnError errorText, pErrorTitle
   if pErrorTitle is empty then put "Error" into pErrorTitle
   put pageArray_Construct (pErrorTitle, errorText) into pageArray
   fedwiki_ReturnPageArray pageArray
   exit to top
end fedwiki_ExitAndReturnError

command fedwiki_ReturnError someValue, errorText
   if someValue is empty then
      fedwiki_ExitAndReturnError errorText, pErrorTitle
   end if
end fedwiki_ReturnError


--> Fedwiki | Overide
-
/*
These handers are overridden using a a frontscript "behavior_RigLocalOveride" and before handlers for testing purposes
*/

command fedwiki_ReturnPageArray pageArray
   if pageArray is not an array then
      put "PageArray is not an array." into someInfo
      put CR & CR & pageArray after someInfo
      put pageArray_Construct ("Error with page array!", someInfo) into pageArray
      put json_FromArray (pageArray) into someJSON
   end if
   
   put json_FromArray (pageArray) into someJSON
   fedwiki_ReturnJSON someJSON
end fedwiki_ReturnPageArray

command fedwiki_ReturnJSON someJSON
   if the environment = "server" then
      put new header "Content-Type: application/json; charset=utf-8"
      put new header "Access-Control-Allow-Origin: *"
      put new header "Access-Control-Allow-Headers: Accept, Authorization, Content-Type"
      put new header "Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE, OPTIONS, LINK, UNLINK"
   end if
   put someJSON
end fedwiki_ReturnJSON

function fedwiki_GetDroppedArray
   -- also good to get a post from a form POST
   fedwiki_SetRawJSON pRawJSON
   put json_ToArray (pRawJSON) into dropArray
   return dropArray
end fedwiki_GetDroppedArray

function fedwiki_GetDroppedUrl
   fedwiki_SetRawJSON rawJSON
   --
   fedwiki_SetDropped rawJSON, droppedURL, droppedHTML, droppedText
   fedwiki_CheckDroppedURL droppedURL, droppedHTML, droppedText
   return droppedURL
end fedwiki_GetDroppedUrl

command fedwiki_CheckDroppedURL @droppedURL, droppedHTML, droppedText
   set the itemdelimiter to "."
   switch
      case droppedURL is not empty
         return "url"
      case droppedHTML is empty
         -- does it begin with "<meta http-equiv=\'Content-Type\' content=\'text/html;charset=UTF-8\'><a href=\"
         put droppedText into droppedURL
         return "text"
      case item -1 of droppedText = "html"
         delete item -1 of droppedText
         set the itemdelimiter to "/"
         put "/view" after item 3 of droppedText
         return "html"
      default
         put "Not a URL dropped on the page!" into errorText
         fedwiki_ExitAndReturnError errorText
         return errorText
   end switch
end fedwiki_CheckDroppedURL

command fedwiki_SetRawJSON @rawJSON
   put $_POST_RAW into rawJSON
   return true
end fedwiki_SetRawJSON

command fedwiki_SetDropped dropJSON, @droppedURL, @droppedHTML, @droppedText
   -- don't use directly as it is used by behavior
   put json_ToArray (dropJSON) into dropArray
   --
   put dropArray ["html"] into droppedHTML
   put dropArray ["text"] into droppedText
   put dropArray ["url"] into droppedURL
   return dropArray
end fedwiki_SetDropped


--> Fedwiki | Overide | Maybe
-
command fedwiki_SetDroppedURL @pDroppedURL
   if pDroppedURL is empty then
      -- sets from real or locally mocked "$_POST_RAW" 
      put fedwiki_GetDroppedUrl() into pDroppedURL
   end if
end fedwiki_SetDroppedURL

command fedwiki_SetDroppedInfo @dropJSON, @droppedURL, @droppedHTML, @droppedText
   fedwiki_SetRawJSON dropJSON
   fedwiki_SetDropped dropJSON, droppedURL, droppedHTML, droppedText
   put the result into dropArray
   return dropArray
end fedwiki_SetDroppedInfo

command fedwiki_DeconstructDroppedURL @pageSlug, @wikiDomain
   put fedwiki_GetDroppedUrl() into droppedURL
   --
   set the itemdelimiter to slash
   put item 3 of droppedURL into wikiDomain
   put item -1 of droppedURL into pageSlug
   --
   set the itemdelimiter to "."
   put item 1 of pageSlug into pageSlug
end fedwiki_DeconstructDroppedURL


--> Fedwiki | Transport | Helpers
-
function fedwiki_MarkdownIndex someIndex, pExtraWords
   -- was "fedwiki_ConstructMarkdownIndex"
   replace comma with CR in someIndex
   repeat for each line someLine in someIndex
      put word 1 to -1 of someLine into domainName
      if domainName is empty then next repeat
      if pExtraWords is not empty then put space & pExtraWords after domainName
      put "- [[" & domainName & "]]" & CR after markdownList
   end repeat
   delete char -1 of markdownList
   return markdownList
end fedwiki_MarkdownIndex

function fedwiki_HkeyMarkdownIndex hkeyIndex
   replace comma with CR in hkeyIndex
   repeat for each line hkey in hkeyIndex
      if hkey is empty then next repeat
      hkey_Deconstruct hKey, hName, hType, hObject, hNum
      put "- [[" & hName & "]]" & CR after markdownList
   end repeat
   delete char -1 of markdownList
   return markdownList
end fedwiki_HkeyMarkdownIndex


--> Fedwiki | Sitemap
-
function fedwiki_GetlastModified wikiDomain
   put fedwiki_FetchSitemapArray (wikiDomain) into sitemapArray
   put fedwiki_SitemapLastModified (sitemapArray) into lastModified
   return lastModified
end fedwiki_GetlastModified

function fedwiki_SitemapLastModified sitemapArray
   put item 2 of the extents of sitemapArray into maxNum
   put 0 into maxUpdate
   repeat with indexNum = 1 to maxNum
      put sitemapArray [indexNum]["slug"] into pageSlug
      put sitemapArray [indexNum]["date"] into lastUpdate
      if lastUpdate > maxUpdate then
         put lastUpdate into maxUpdate
      end if
   end repeat
   return maxUpdate
end fedwiki_SitemapLastModified

function fedwiki_ListSitemapPages wikiDomain
   put fedwiki_FetchSitemapArray (wikiDomain) into sitemapArray
   repeat for each key indexNum in sitemapArray
      put sitemapArray [indexNum]["title"] into pageTitle
      put pageTitle & CR after pageTitles
   end repeat
   delete char -1 of pageTitles
   return pageTitles
end fedwiki_ListSitemapPages

function fedwiki_ListSitemapSlugs wikiDomain
   put fedwiki_FetchSitemapArray (wikiDomain) into sitemapArray
   repeat for each key indexNum in sitemapArray
      put sitemapArray [indexNum]["slug"] into pageSlug
      put pageSlug & CR after pageSlugs
   end repeat
   delete char -1 of pageSlugs
   return pageSlugs
end fedwiki_ListSitemapSlugs

function fedwiki_SearchSitemapArray pageSlug, siteMapArray
   -- was "fedwiki_FindSlug"
   repeat for each key indexNum in siteMapArray
      if siteMapArray [indexNum]["slug"] is pageSlug then
         return indexNum
      end if
   end repeat
   return 0
end fedwiki_SearchSitemapArray

function fedwiki_FetchSitemapArray wikiDomain, pLoad
   put fedwiki_FetchSitemap (wikiDomain, pLoad) into someJson
   if someJson is empty then return empty
   put json_ToArray (someJson) into sitemapArray
   if sitemapArray is false then return empty
   return sitemapArray
end fedwiki_FetchSitemapArray

function fedwiki_FetchSitemap fedwikiDomain, pLoad
   put fedwiki_JsonSiteMapUrl (fedwikiDomain) into sitemapURL
   if pLoad is true then load url sitemapURL
   put url sitemapURL into sitemapJSON
   return sitemapJSON
end fedwiki_FetchSitemap


--> Fedwiki
-
function fedwiki_GetLinks wikiText
   local sNum, eNum
   -- put ".+" into notBracket
   -- put "\[\[([^\]]+)\|([^\]]+)\]\]" into someReg
   
   put "[^\]]+" into notBracket
   put "\[\[(" & notBracket & ")\]\]" into someReg
   repeat
      get matchchunk (wikiText, someReg, sNum, eNum) 
      if it is true then
         put char sNum to eNum of wikiText into pageTitle
         put pageTitle & CR after pageTitles
         --
         delete char 1 to eNum of wikiText
      else 
         exit repeat
      end if
   end repeat
   delete char -1 of pageTitles
   return pageTitles
end fedwiki_GetLinks

command fedwiki_ReplaceExternalLinks @wikiText
   -- in public - [https://upload.wikimedia.org/wikipedia/commons/9/9c/Open_Science_-_Prinzipien.png wikimedia.org]
   put "(\[http.+\])" into someReg
   
   local refStart, refEnd
   put 0 into indexNum
   repeat
      get matchchunk (wikiText, someReg, sNum, eNum) 
      if it is true then
         add 1 to indexNum
         put char sNum to eNum of wikiText into extLinkText
         delete char - 1 of extLinkText
         delete char 1 of extLinkText
         put word 1 of extLinkText into extLinkURL
         put word 2 to -1 of extLinkText into extLinkText
         --
         -- - [wikimedia.org](https://upload.wikimedia.org/wikipedia/commons/9/9c/Open_Science_-_Prinzipien.png)
         put "[" & extLinkText & "](" & extLinkURL & ")" into markdownLink
         put markdownLink into char sNum to eNum of wikiText
      else
         exit repeat
      end if
   end repeat
   return indexNum
end fedwiki_ReplaceExternalLinks

command fedwiki_ForwardAndReturn restURL
   put fedwiki_ForwardJSON (restURL) into pageJSON
   fedwiki_ReturnJSON pageJSON
end fedwiki_ForwardAndReturn

function fedwiki_ForwardJSON restURL
   fedwiki_SetRawJSON dropJSON
   fedwiki_PostJSON dropJSON, restURL
   put the result into pageJSON
   return pageJSON
end fedwiki_ForwardJSON

command fedwiki_SetDroppedFaviconInfo @pageSlug, @fedwikiDomain, pDoubleCheck
   -- safe double check thing
   fedwiki_SetRawJSON dropJSON
   --
   put fedwiki_IsFaviconDrop (dropJSON) into isFavicon
   if isFavicon is false then
      put empty into pageSlug
      put empty into fedwikiDomain 
      return false
   end if
   
   put fedwiki_GetDroppedUrl() into droppedURL
   set the itemDelimiter to "/"
   put item 3 of droppedURL into fedwikiDomain
   put item -1 of droppedURL into pageSlug
   replace ".html" with empty in pageSlug
   
   if pDoubleCheck is not true then return true
   
   -- let's check it is a wiki domain
   -- pageSlug may be a ghost page so don't check that
   put fedwiki_PageExists (fedwikiDomain) into isWiki
   if isWiki then
      return true
   else
      put empty into pageSlug
      put empty into fedwikiDomain 
      return false
   end if
end fedwiki_SetDroppedFaviconInfo


--> Fedwiki | URL | Drop
-
command fedwiki_DeconstructDropped @droppedText, @droppedHtml, @droppedURL
   put fedwiki_GetDroppedArray ($_POST_RAW) into dropArray
   put dropArray ["text"] into droppedText
   put dropArray ["html"] into droppedHtml
   put dropArray ["url"] into droppedURL
   return dropArray
end fedwiki_DeconstructDropped


--> Fedwiki | Fetch | Drop
-
function fedwiki_FetchDroppedPageJson droppedURL, pSlug
   set the itemdelimiter to "."
   switch
      case pSlug is empty and item -1 of droppedURL = "html"
         return fedwiki_FetchDroppedFlagJson (droppedURL)
         break
      case pSlug is empty
         put fedwiki_FetchLastLineUpJson (droppedURL) into pageJson
         break
      default
         put fedwiki_FetchPageJson (fedwikiDomain, pSlug) into pageJson
   end switch
   return pageJson
end fedwiki_FetchDroppedPageJson

function fedwiki_FetchDroppedFlagJson droppedURL
   set the itemdelimiter to slash
   if not (the number of items of droppedURL > 3) then return empty
   put item 3 of droppedURL into fedwikiDomain
   put item -1 of droppedURL into pSlug
   --
   set the itemdelimiter to "."
   put item 1 of pSlug into pSlug
   --
   put fedwiki_FetchPageJson (fedwikiDomain, pSlug) into pageJson
   return pageJson
end fedwiki_FetchDroppedFlagJson


--> Fedwiki | Fetch
-
function fedwiki_FetchLastLineUpArray droppedURL, pNotTheseSlugs
   put fedwiki_FetchLastLineUpJson (droppedURL, pNotTheseSlugs) into pageJSON
   put json_ToArray (pageJSON) into pageArray
   return pageArray
end fedwiki_FetchLastLineUpArray

function fedwiki_FetchLastLineUpJson droppedURL, pNotTheseSlugs
   -- does not check that droppedURL is not a ".html" page
   if pNotTheseSlugs is empty then put "journal-cleaner-transport" into pNotTheseSlugs
   
   put fedwiki_ConstructUrlArray (droppedURL) into urlArray
   if urlArray is false then return false
   
   put item 2 of the extents of urlArray into lineUpNum
   put urlArray [lineUpNum]["pageSlug"] into pageSlug
   if pageSlug is among the items of pNotTheseSlugs and lineUpNum is not 1 then
      subtract 1 from lineUpNum
   end if
   
   put fedwiki_FetchLineUpJson (urlArray, lineUpNum) into pageJSON
   return pageJSON
end fedwiki_FetchLastLineUpJson

function fedwiki_FetchLineUpJson urlArray, lineUpNum
   if lineUpNum = -1 then put item 2 of the extents of urlArray into lineUpNum
   
   put urlArray [lineUpNum]["pageSlug"] into pageSlug
   put urlArray [lineUpNum]["someDomain"] into someDomain
   
   -- http://forage.david.bovill.me/entry-level-browser.json?random=72428048
   put "http://" & someDomain & "/" & pageSlug & ".json" into someUrl
   -- put "?random=" & the milliseconds after someUrl
   put url someUrl into someJSON
   return someJSON
end fedwiki_FetchLineUpJson


--> Fedwiki | Exists
-
function fedwiki_PageExists wikiDomain, pSlug
   put pageArray_Fetch (wikiDomain, pSlug) into pageArray 
   put pageArray is not empty into someBoolean
   return someBoolean
end fedwiki_PageExists

function fedwiki_WikiExists someDomain
   put fedwiki_FetchSitemapArray (someDomain) into sitemapArray
   put sitemapArray is an array into someBoolean
   return someBoolean
end fedwiki_WikiExists

function fedwiki_IsJsonUrl jsonURL
   -- http://openscience.cc/maven-science.json
   put "http://(.+)/(.+).json" into someReg
   if matchtext (jsonURL, someReg, wikiDomain, pageSlug) is false then
      -- if not (jsonURL ends with ".json") then
      put empty into pageTitle
      put empty into storyArray
      put empty into journalArray
      return false
   else
      return true
   end if
end fedwiki_IsJsonUrl


--> Fedwiki | Tests
-
function fedwiki_IsFaviconDrop dropJSON
   -- dropJSON is not longer optional
   if dropJSON is empty then return false
   
   -- tests depends on different behaviors of browsers
   if the environment = "server" then
      rigLoaderLoadLibrary "Useragent"
      put rigBrowser() into tBrowser
   else
      put empty into tBrowser
   end if
   
   put fedwiki_GetDroppedArray (dropJSON) into dropArray
   put dropArray ["html"] into droppedHtml
   put revXMLCreateTree (droppedHtml, false, true, false) into treeID
   switch tBrowser
      case "Firefox"
         put revXMLAttribute (treeID, "/h1/a/img", "class") into favClass
         put revXMLAttribute (treeID, "/h1/a/img", "height") into favHeight
         break
      case "Safari"
         put revXMLAttribute (treeID, "/img", "class") into favClass
         put revXMLAttribute (treeID, "/img", "height") into favHeight
         break
         -- case "Chrome"
      default
         put revXMLAttribute (treeID, "/meta/img", "class") into favClass
         put revXMLAttribute (treeID, "/meta/img", "height") into favHeight
         break
   end switch
   revDeleteXMLTree treeID
   put favClass = "favicon" and favHeight = "32px" into isFavicon
   --
   return isFavicon
end fedwiki_IsFaviconDrop

command fedwiki_FilterCheck @wikiDomains
   repeat for each line wikiDomain in wikiDomains
      set the cursor to busy
      if fedwiki_WikiExists (wikiDomain) is true then
         put wikiDomain & CR after goodDomains
      else
         put wikiDomain & CR after badDomains
      end if
   end repeat
   delete char -1 of goodDomains
   delete char -1 of badDomains
   put goodDomains into wikiDomains
   return badDomains
end fedwiki_FilterCheck

function fedwiki_IsHtmlUrl wikiPageURL, @errorMsg
   -- http://tools.progressivedemocracy.cc/collaborative-bookmarking.html
   set the itemdelimiter to slash
   if the number of items of wikiPageURL is not 4 then
      put "Error, dropped url is not a single .html wiki page" into errorMsg
      return false
   end if
   
   set the itemdelimiter to "."
   if item -1 of wikiPageURL is not "html" then
      put "Error, dropped url is not a single .html wiki page" into errorMsg
      return false
   end if
   
   return true
end fedwiki_IsHtmlUrl


--> Fedwiki | List
-
function fedwiki_ConstructImageLinkTag pCaptionLinkURL
   put html_ExtractTLD (pCaptionLinkURL, true) into linkTag
   switch linkTag
      case "wikipedia.org"
         return "wikipedia"
         break
      case "wikimedia.org"
         return "wikimedia"
         break
      default
         return linkTag
   end switch
end fedwiki_ConstructImageLinkTag

function fedwiki_HtmlToMarkdown htmlSnippet
   -- depends on lib_Encoding
   -- for now strip and return text
   text_HtmlEntityEscape htmlSnippet
   put text_StripAllTags (htmlSnippet) into refText
   replace CR with empty in refText
   put json_Utf8Encode (refText) into refText
   return refText
end fedwiki_HtmlToMarkdown

function fedwiki_ConstructSlug pageTitle
   -- it is very annoying that "_" is not an allowed character
   replace space with "-" in pageTitle
   repeat for each char someChar in  "()_|.,:;"
      replace someChar with empty in pageTitle
   end repeat
   put tolower (pageTitle) into pageSlug
   return pageSlug
end fedwiki_ConstructSlug

function fedwiki_ConstructTitle pageSlug
   replace "-" with space in pageSlug
   repeat for each word someWord in pageSlug
      put toupper (char 1 of someWord) into char 1 of someWord
      put someWord & space after pageTitle
   end repeat
   delete char -1 of pageTitle
   return pageTitle
end fedwiki_ConstructTitle


--> Fedwiki | JSON Plugin
-
function fedwiki_FetchPluginJSON pageSlug, wikiDomain
   put fedwiki_ConstructPluginJsonUrl (pageSlug, wikiDomain) into restURL
   put url restURL into someJSON
   -- put jsonrpc_Get (restURL) into someJSON
   return someJSON
end fedwiki_FetchPluginJSON

command fedwiki_PutPluginJSON someJSON, pageSlug, wikiDomain, apiKey
   -- for http://admin.fedwiki.org/json-plugin.html
   
   put fedwiki_ConstructPluginJsonUrl (pageSlug, wikiDomain) into restURL
   --
   put "Content-type: application/json" into newHeaders
   put CR & "Accept: application/json" after newHeaders
   put CR & "Accept-Charset: utf-8" after newHeaders
   put CR & "X-Api-Key:" && apiKey after newHeaders
   set the httpheaders to newHeaders
   --
   -- replace "'" with quote in someJSON
   --
   put someJSON into url restURL
   --
   put the result into putResult
   /*
   -- this should return, but is returning only error msg I think
   {
   "status": "ok",
   "writes": 3330,
   "interval": 299524,
   "length": 17736
   }
   */
   return putResult
end fedwiki_PutPluginJSON

function fedwiki_ConstructPluginJsonUrl pageSlug, wikiDomain
   -- http://admin.fedwiki.org/plugin/json/atopia-fedwiki-sites
   put "http://" & wikiDomain & "/plugin/json/" & pageSlug into restURL
   return restURL
end fedwiki_ConstructPluginJsonUrl


--> Fedwiki | Post
-
command fedwiki_PostJSON someJSON, restURL
   set the httpheaders to "Content-Type: application/json" -- required for revIgnitor
   post someJSON to url restURL
   put it into jsonResult
   return jsonResult
end fedwiki_PostJSON

function fedwiki_EncodePost someText, pSomeURL
   -- {"text":"Ant","html":""}
   
   put someText into postArray ["text"]
   put empty into postArray ["html"]
   if pSomeURL is not empty then
      put pSomeURL into postArray ["url"]
   end if
   put json_FromArray (postArray) into postJSON
   return postJSON
end fedwiki_EncodePost

function fedwiki_ProcessPost pPostJSON
   /*
   A Transporter posts json to a REST endpoint with a structure something like:
   -- {"text":"Ant","html":""}
   
   Use this function to extract the text value posted.
   A tranporter will set the dropped url to the text value, but your own scripts can set it to whatever you like
   usefull for forwarding values toother transporters
   */
   if pPostJSON is empty then put $_POST_RAW into pPostJSON
   
   put json_ToArray (pPostJSON) into postArray
   if postArray is an array then
      put postArray ["text"] into someText
   else
      -- don't post raw text unless you have to
      -- use fedwiki_EncodePost()
      put $_POST_RAW into someText
   end if
   return someText
end fedwiki_ProcessPost


--> Fedwiki | Create
-
function fedwiki_CreateMarkdownPageArray pageTitle, pageDescription
   put pageTitle into pageArray ["title"]
   put pageArray_ConstructJournal (pageTitle) into pageArray ["journal"]
   pageArray_AddMarkdown pageArray, pageDescription
   return pageArray
end fedwiki_CreateMarkdownPageArray

function fedwiki_CreateHtmlPageArray pageTitle, someHTML
   -- not such a good idea to have HTML as first paragraph?
   put pageTitle into pageArray ["title"]
   put pageArray_ConstructJournal (pageTitle) into pageArray ["journal"] 
   pageArray_AddHtml pageArray, someHTML
   return pageArray
end fedwiki_CreateHtmlPageArray

function fedwiki_CreatePageAndImageArray pageTitle, pageDescription, droppedURL, pImageURL, pShortDescription
   local pageArray
   fedwiki_CreateFirstParagraph pageTitle, pageDescription, droppedURL, pageArray
   put the result into extraLines
   --
   if pShortDescription is empty then put pageDescription into pShortDescription
   fedwiki_AddImageToPageArray pageArray, pImageURL, pShortDescription, droppedURL
   --
   fedwiki_AutoAddLines pageArray, extraLines
   return pageArray
end fedwiki_CreatePageAndImageArray

command fedwiki_CreateFirstParagraph pageTitle, pageDescription, someURL, @pageArray
   put html_ExtractTLD (someURL, true) into tldBit
   --
   put text_SplitIntoParagraphs (pageDescription) into splitText
   put word 1 to -1 of line 1 to 2 of splitText into firstParagraph
   delete line 1 to 2 of splitText
   --
   fedwiki_AddExternalLink firstParagraph, someURL
   --
   put fedwiki_ConstructNewPageArray (pageTitle, firstParagraph) into pageArray
   return splitText
end fedwiki_CreateFirstParagraph


--> Fedwiki | Ref Plugin
-
function fedwiki_ConstructMarkdownLine someTitle, externalURL
   fedwiki_AddExternalLink someTitle, externalURL
   put "-" && someTitle into someMarkdown
   return someMarkdown
end fedwiki_ConstructMarkdownLine

function fedwiki_ConstructMarkdownPage someMarkdown, pPageTitle
   put word 1 to -1 of someMarkdown into someMarkdown
   if pPageTitle is empty then
      put line 1 of someMarkdown into pPageTitle
      if word 1 of pPageTitle = "#" then
         put word 2 to -1 of pPageTitle into pPageTitle
      end if
      delete line 1 of someMarkdown
   end if
   put pageArray_Construct (pPageTitle) into pageArray
   --
   
   repeat for each line downLine in someMarkdown
      put word 1 to -1 of downLine into downLine
      switch
         case downLine is empty
            next repeat
            break
         case matchtext (downLine, "\[ \] \[\+(.+)\]\((.+)\)", linkTitle, paperURL)
            -- [ ] [+The Broker](https://paper.dropbox.com/doc/The-Broker-cimRsgytz3lWMfk64uqLt) 
            put "- [ ] [[" & linkTitle & "]]" && "- [" & paperURL && "paper]" into fixedLine
            pageArray_AddMarkdown pageArray, fixedLine
            break
         case matchtext (downLine, "- \[\+(.+)\]\((.+)\)", linkTitle, paperURL)
            -- - [+The Scribe](https://paper.dropbox.com/doc/The-Scribe-RPCzb4JF6IMvw9L6Zcfn6)
            put "- [[" & linkTitle & "]]" && "- [" & paperURL && "paper]" into fixedLine
            pageArray_AddMarkdown pageArray, fixedLine
            break
         case downLine begins with "[x]"
            -- [x] @Charlotte C embed the audio in each of the Paper docs above
         case downLine begins with "[ ]"
            put "-" && downLine into fixedLine
            pageArray_AddMarkdown pageArray, fixedLine
            break
         case matchtext (downLine, "\!\[.*\]\((.+)\)", imageURL)
            -- ![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Panton_Principles.jpg/420px-Panton_Principles.jpg)
            
            -- could get next line as caption?
            -- put fedwiki_ConstructImageHtml (imageURL, pCaption, pCaptionLinkURL, pLinkToImage) into imageHtml
            put html_ConstructImageDiv (imageURL) into imageHtml
            --
            pageArray_AddHtml pageArray, imageHtml
            break
         default
            pageArray_AddMarkdown pageArray, downLine
      end switch
   end repeat
   return pageArray
end fedwiki_ConstructMarkdownPage

function fedwiki_ConstructNewPageJson pageTitle, pSomeText
   put fedwiki_ConstructNewPageArray (pageTitle, pSomeText) into pageArray
   put json_FromArray (pageArray) into pageJSON
   return pageJSON
end fedwiki_ConstructNewPageJson

function fedwiki_ConstructNewPageArray pageTitle, pSomeText, pSourceArray
   put pageTitle into pageArray ["title"]
   put pageArray_ConstructJournal (pageTitle, pSourceArray) into pageArray ["journal"] 
   if pSomeText is empty then
      pageArray_AddFactory pageArray
   else
      pageArray_AddMarkdown pageArray, pSomeText
   end if
   return pageArray
end fedwiki_ConstructNewPageArray


--> Fedwiki | Add | Lines
-
function fedwiki_ConstructImageHtml imageURL, pCaption, pCaptionLinkURL, pLinkToImage
   if pCaption is empty then put "Transported Image - " into pCaption
   if pCaptionLinkURL is empty then put imageURL into pCaptionLinkURL
   put "100%" into pWidth
   html_TopAndTailParagraphTags pCaption
   if char -1 of pCaption = "." then delete char -1 of pCaption
   
   put "<div style='padding: 12px; background:#eee; width:96%; align=centered;'>" into someHTML
   if pLinkToImage is false then
      put CR & "<a href='" & pCaptionLinkURL & "' target='_blank'>" after someHTML
   else
      put CR & "<a href='" & imageURL & "' target='_blank'>" after someHTML
   end if
   --
   put CR & "<img style='display:block; margin:auto; width:" & pWidth & ";'" after someHTML
   put CR & "src='" & imageURL & "'>" after someHTML
   --
   put CR & "</a>" after someHTML
   put CR after someHTML
   put CR & "<p class=caption>" after someHTML
   put CR & pCaption after someHTML
   --
   put fedwiki_ConstructImageLinkTag (pCaptionLinkURL) into linkTag
   put CR & "- [" & pCaptionLinkURL && linkTag & "]" after someHTML
   --
   put CR & "</p></div>" after someHTML
   return someHTML
end fedwiki_ConstructImageHtml

command fedwiki_AutoAddLines @pageArray, someLines
   repeat
      get line 1 to 2 of someLines
      replace CR with space in it
      if it is not empty then
         pageArray_AddText pageArray, it
      end if
      delete line 1 to 2 of someLines
      if someLines is empty then
         exit repeat
      end if
   end repeat
end fedwiki_AutoAddLines


--> Fedwiki | Edit
-
command fedwiki_AddTools @fedwikiPageArray, pSearchWords
   put "# Tools" into someMarkdown
   if pSearchWords is not empty then
      put google_ConstructCreativeCommonsSearchUrl (pSearchWords) into searchURL
      put CR & CR & "Search for [[free culture]] images for this page on [" & searchURL && "google]" after someMarkdown
   end if
   
   pageArray_AddMarkdown fedwikiPageArray, someMarkdown
   pageArray_AddTransport fedwikiPageArray
   -- fedwiki_AddCreativeCommonsSearch fedwikiPageArray, searchWords
end fedwiki_AddTools

command fedwiki_AddCreativeCommonsSearch @fedwikiPageArray, searchWords
   put google_ConstructCreativeCommonsSearchUrl (searchWords) into searchURL
   put "Search for [[free culture]] images for this page on [" & searchURL && "google]" into someMarkdown
   pageArray_AddMarkdown fedwikiPageArray, someMarkdown
end fedwiki_AddCreativeCommonsSearch

command fedwiki_AddExternalLinkToFirstSection @fedwikiPageArray, someURL, pLinkText
   if pLinkText is empty then put "wikipedia" into pLinkText
   
   put fedwikiPageArray ["story"] into storyArray
   put storyArray [1]["text"] into itemText
   --
   if itemText begins with "# Tools" then
      -- section was empty
      put "There is no text for this section. Please add some." into itemText
      fedwiki_AddExternalLink itemText, someURL, pLinkText
      put pageArray_ConstructItemArray (itemText, "markdown") into itemArray
      --
      fedwiki_StoryInsertInto storyArray, 1, itemArray
      --
      put storyArray into fedwikiPageArray ["story"]
   else -- could do more checking of itemType
      fedwiki_AddExternalLink itemText, someURL, pLinkText
      put itemText into fedwikiPageArray ["story"][1]["text"]
   end if
end fedwiki_AddExternalLinkToFirstSection

command fedwiki_MakeTextParagraphFirst @fedwikiPageArray, pTypeList
   if pTypeList is empty then put "paragraph,markdown" into pTypeList
   
   put fedwikiPageArray ["story"] into storyArray
   repeat with itemNum = 1 to (the number of lines of the keys of storyArray)
      put storyArray [itemNum]["type"] into itemType
      if itemType is among the items of pTypeList then
         pageArray_MoveItem fedwikiPageArray, itemNum, 1
         return true
      end if
   end repeat
   return false
end fedwiki_MakeTextParagraphFirst

function fedwiki_FindFirstPicture fedwikiPageArray
   put fedwikiPageArray ["story"] into storyArray
   put item 2 of the extents of storyArray into maxItem
   repeat with itemNum = 1 to maxItem
      switch storyArray [itemNum]["type"]
         case "html"
            get storyArray [itemNum]["text"]
            switch
               case it begins with "<video src="
               case it begins with "<div style='padding: 12px; background:#eee; width:96%; align=centered;'>"
                  return itemNum
            end switch
            return 0
         case "video"
         case "image"
            return itemNum
      end switch
   end repeat
   return 0
end fedwiki_FindFirstPicture


--> Fedwiki | StoryArray | Edit
-
command fedwiki_StoryInsertAfter @storyArray, afterNum, itemArray
   put afterNum + 1 into intoNum
   fedwiki_StoryInsertInto storyArray, intoNum, itemArray
end fedwiki_StoryInsertAfter

command fedwiki_StoryInsertInto @storyArray, intoNum, itemArray
   put item 2 of the extents of storyArray into maxItem
   
   -- move items below intoNum down 1
   repeat with itemNumToMove = maxItem down to intoNum
      put itemNumToMove + 1 into itemNumDestination
      put storyArray [itemNumToMove] into storyArray [itemNumDestination]
   end repeat
   
   -- now insert itemArray into item intoNum of storyArray
   put itemArray into storyArray [intoNum]
end fedwiki_StoryInsertInto

function fedwiki_StoryExtractorderedIDArray storyArray
   put item 2 of the extents of storyArray into maxItem
   repeat with itemNum = 1 to maxItem
      put storyArray [itemNum]["id"] into storyID
      put storyID into oderedIdArray [itemNum]
   end repeat
   return oderedIDArray
end fedwiki_StoryExtractorderedIDArray


--> Fedwiki | Parse
-
function fedwiki_ParseHtml someHTML
   /*
   Video embeds not rendered without closing div tag
   
   <div class="item"><p>YOUTUBE SYsy6qbKp3Y
   Is Market Capitalism simply an accident of certain factors that came together in the 19th and 20th centuries? - <a class="external" target="_blank" 
   href="https://www.youtube.com/channel/UCp5hG8rt1z2MJ9aNVxY2Xdg" title="https://www.youtube.com/channel/UCp5hG8rt1z2MJ9aNVxY2Xdg" rel="nofollow">youtube 
   <img src="/images/external-link-ltr-icon.png"/></a></p><div class="item paragraph"><p>Underlying the seismic sh
   */
   html_Tidy someHTML -- fixes closing div tags
   
   put revXMLCreateTree (someHTML, false, true, false) into treeID
   --
   put revXMLRootNode (treeID) into rootNode
   put revXMLMatchingNode (treeID, rootNode, "div", "class", "story", -1, false) into storyNode
   
   -- could probably do this simpler now that we have fixed div tags
   put revXMLChildContents (treeID, storyNode, tab, return, "relative", -1) into childContents
   
   put 1 into divNum
   set the itemdelimiter to tab
   repeat for each line childInfo in childContents
      put item 1 of childInfo into relativeNode
      if char -1 of relativeNode is not "]" then next repeat -- quick hack
      
      put storyNode & slash & relativeNode into someNode
      put revXmlText (treeID, someNode) into someText
      put someText into htmlArray [divNum]
      add 1 to divNum
   end repeat
   --
   revDeleteXMLTree treeID
   return htmlArray
end fedwiki_ParseHtml

function fedwiki_ItemChecked pageArray, checkboxTitle
   put pageArray ["story"] into storyArray
   put item 2 of the extents of storyArray into maxItemNum
   repeat with itemNum = 1 to maxItemNum
      put storyArray [itemNum] into itemArray
      if itemArray ["type"] is not "markdown" then next repeat
      
      put itemArray ["text"] into itemText
      switch
         case itemText contains ("- [x]" && checkboxTitle)
            return true
         case itemText contains ("- [ ]" && checkboxTitle)
            return false
         default
            next repeat
      end switch
   end repeat
   return false
end fedwiki_ItemChecked


--> Fedwiki | Fetch
-
function fedwiki_FetchFavicon fedwikiDomain
   put fedwiki_FaviconURL (fedwikiDomain) into someUrl
   put url someUrl into pngData
   return pngData
end fedwiki_FetchFavicon

function fedwiki_FetchSiteExport fedwikiDomain
   -- load if you want better responsiveness
   put fedwiki_JsonSiteExportUrl (fedwikiDomain) into someUrl
   put url someUrl into someJSON
   return someJSON
end fedwiki_FetchSiteExport

function fedwiki_FetchMetadataArray someURL
   set the itemdelimiter to "."
   if item -1 of someURL = "html" then
      put "json" into item -1 of someURL
   else
      set the itemdelimiter to "/"
      put item -1 of someURL into pageSlug
      put item 1 to 3 of someURL into rootURL
      put rootURL & "/" & pageSlug & ".json" into someURL
   end if
   put url someURL into someJSON
   
   put json_ToArray (someJSON) into fedwikiPageArray
   put fedwikiPageArray  ["title"] into someTitle
   if someTitle is empty then return empty
   put fedwikiPageArray ["metadata"] into metadataArray
   put someTitle into metadataArray ["pageTitle"]
   return metadataArray
end fedwiki_FetchMetadataArray

function fedwiki_FetchTitle someURL
   set the itemdelimiter to "."
   put "json" into item -1 of someURL
   put url someURL into someJSON
   
   put json_ToArray (someJSON) into fedwikiPageArray
   put keys (fedwikiPageArray) into wikiKeys
   repeat for each item someKey in "title,journal,story"
      if someKey is not among the lines of wikiKeys then 
         return empty
      end if 
   end repeat
   return fedwikiPageArray ["title"]
end fedwiki_FetchTitle


--> Fedwiki | Metadata
-
command fedwiki_DeconstructCreateArray createArray, @parentTitle, @sectionTitle, @transportURL, @sourceURL, @pageTitle, @linkDictionary
   put createArray ["title"] into sectionTitle
   put createArray ["create"]["item"]["title"] into parentTitle
   put createArray ["create"]["source"] into sourceArray
   
   put sourceArray ["transport"] into transportURL
   put sourceArray ["url"] into sourceURL
   put sourceArray ["pageTitle"] into pageTitle
   put sourceArray ["link_Dictionary"] into linkDictionary
   return sourceArray
end fedwiki_DeconstructCreateArray


--> Fedwiki | Lineup
-
function fedwiki_ExtractFirstStoryItem pageArray, itemType
   put pageArray ["story"] into storyArray
   put item 2 of the extents of storyArray into lastItemNum
   repeat with itemNum = 1 to lastItemNum
      put storyArray [itemNum] into itemArray
      if itemArray ["type"] = itemType then
         put itemArray ["text"] into someData
         return someData
      end if
   end repeat
   return empty
end fedwiki_ExtractFirstStoryItem


--> Fedwiki | Add | Image
-
command fedwiki_AddImageToPageArray @pageArray, imageURL, pCaption, pCaptionLinkURL
   if imageURL is  empty then return false
   if pageArray is not an array then  return false
   -- put "This is a simple image dropped on to a wiki." into pageText
   -- put fedwiki_ConstructNewPageArray ("Dropped Image", pageText) into pageArray
   --
   if pCaption is empty then
      put "This is an image" into pCaption
   else if the number of words of pCaption > 35 then
      put word 1 to 35 of pCaption & "..." into pCaption
   else
      put word 1 to -1 of pCaption into pCaption
   end if
   --
   if pCaptionLinkURL is empty then
      put imageURL into pCaptionLinkURL
   end if
   put html_ExtractTLD (pCaptionLinkURL, true) into tldBit
   put " -" && tldBit into linkInfo
   --
   put fedwiki_ConstructImageHtml (imageURL, pCaption, pCaptionLinkURL, linkInfo) into imageHTML
   pageArray_AddHtml pageArray, imageHTML
   return true
end fedwiki_AddImageToPageArray

command fedwiki_AddExternalLink @someText, someURL, pLinkText
   if someURL is empty then return false
   
   if pLinkText is empty then
      -- put html_ExtractTLD (someURL) into pLinkText
      set the itemdelimiter to slash
      get item 3 of someURL
      set the itemdelimiter to "."
      switch
         case item -2 of it = "wikipedia"
            put "wikipedia" into pLinkText
            break
         case item -2 of it = "wikicommons"
            put "wikicommons" into pLinkText
            break
         default
            put item -2 to -1 of it into pLinkText
      end switch
   end if
   
   -- put word 1 to -1 of line 1 of someText into someText
   put word 1 to -1 of someText into someText
   if char -1 of someText is among the chars of ".:;" then
      delete char -1 of someText
   end if
   put someText && "- [" & someURL && pLinkText & "]" into someText
   --
   return true
end fedwiki_AddExternalLink


--> Fedwiki | Add | Array
-
command fedwiki_AddStoryArray @fedwikiPageArray, moreStoryItemArray
   if moreStoryItemArray is not an array then return false
   -- add multiple new storyItemArrays from moreStoryItemArray to end of fedwikiPageArray story
   put fedwikiPageArray ["story"] into storyItemArray
   fedwiki_AddToStoryArrayItems storyItemArray, moreStoryItemArray
   put storyItemArray into fedwikiPageArray ["story"]
   --
   pageArray_StripJournal fedwikiPageArray
   return true
end fedwiki_AddStoryArray

command fedwiki_AddToStoryArrayItems @storyItemArray, moreStoryItemArray
   if moreStoryItemArray is not an array then return false
   repeat with storyItemNum = 1 to item 2 of the extents of moreStoryItemArray
      put moreStoryItemArray [storyItemNum] into itemArray
      array_AddToEndOfIndex itemArray, storyItemArray
   end repeat
   return true
end fedwiki_AddToStoryArrayItems


--> Fedwiki | Journal | Array | Create
-
command fedwiki_AddToCreateArray @fedwikiPageArray, someArray
   put fedwikiPageArray ["journal"]["source"] into sourceArray
   union sourceArray with someArray
   put sourceArray into fedwikiPageArray ["journal"]["source"]
end fedwiki_AddToCreateArray


--> Fedwiki | Journal | Array | Construct
-
function fedwiki_ConstructForkItemArray wikiDomain, pForkDate
   if pForkDate is empty then put the milliseconds into pForkDate
   put wikiDomain into itemArray ["site"]
   put "fork" into itemArray ["type"]
   put pForkDate into itemArray ["date"]
   return itemArray
end fedwiki_ConstructForkItemArray

function fedwiki_ConstructCreateSourceArray transportURL, sourceURL, pDateTransported, pRepo, pRevisionID
   /*
   url = "https://en.wikipedia.org/wiki/Hypertext"
   date = 1458105780000
   rev = "v128.397"
   transport = "http://localhost:4020/proxy"
   repo = "https://github.com/ward/transport-proxy"
   */
   if pDateTransported is empty then put the milliseconds into pDateTransported
   
   put sourceURL into createSourceArray ["url"]
   put transportURL into createSourceArray ["transport"]
   put pDateTransported into createSourceArray ["date"]
   
   if pRepo is not empty then put pRepo into createSourceArray ["repo"]
   if pRevisionID is not empty then put pRevisionID into createSourceArray ["rev"]
   
   return createSourceArray
end fedwiki_ConstructCreateSourceArray


--> Fedwiki | Construct | Array
-
function fedwiki_ConstructNewImagePageArray pageTitle, someImage, imageType, pImageCaption, pSourceArray
   local fedwikiPageArray, journalArray
   
   put pageTitle into fedwikiPageArray ["title"]  
   put fedwiki_ConstructEncodedImageArray (someImage, imageType, pImageCaption) into imageArray
   pageArray_AddItemArray imageArray, fedwikiPageArray
   
   put pageArray_ConstructJournal (pageTitle, pSourceArray) into journalArray
   journalArray_Add journalArray, imageArray, "add"
   put journalArray into fedwikiPageArray ["journal"] 
   
   return fedwikiPageArray
end fedwiki_ConstructNewImagePageArray

function fedwiki_ConstructEncodedImageArray someImage, imageType, pImageCaption, pID   
   pageArray_AssignID pID
   if pImageCaption is empty then put "Uploaded image" into pImageCaption
   
   put "Uploaded image" into imageArray ["caption"] 
   put pID into imageArray ["id"]
   put pImageCaption into imageArray ["text"] 
   put "image" into imageArray ["type"] 
   
   put "data:image/" & imageType & ";base64," into dataImageUrl
   put base64encode (someImage) after dataImageUrl
   put dataImageUrl into imageArray ["url"] 
   
   return imageArray
end fedwiki_ConstructEncodedImageArray


--> Fedwiki | Construct | HTML
-
function fedwiki_ConstructLink someText, pExternalURL
   put word 1 to -1 of line 1 of someText into someText
   if pExternalURL is empty then
      return "[[" & someText & "]]"
   else
      put word 1 to -1 of pExternalURL into pExternalURL
      return "[" & pExternalURL && someText & "]"
   end if
end fedwiki_ConstructLink

function fedwiki_ConstructImageDiv imageURL, imageHREF
   if imageHREF is empty then
      put "<img src=" & kwote (imageURL) & " width=100%>" into imageHTML
      -- put "<div align=center><img src=" & kwote (imageURL) & " width=428></div>" into imageHTML
   else
      put "<a href="  & kwote (imageHREF) & "target=" & kwote("_blank") & "><img src=" & kwote (imageURL) & " width=100%></a>" into imageHTML
      -- put "<div align=center><a href="  & kwote (imageHREF) & "target=" & kwote("_blank") & "><img src=" & kwote (imageURL) & " width=428></a></div>" into imageHTML
   end if
   return imageHTML
end fedwiki_ConstructImageDiv


--> Fedwiki | Construct
-
function fedwiki_ConstructSiteMapTitleArray sitemapArray
   repeat for each key itemNum in sitemapArray
      put sitemapArray [itemNum] into itemArray
      --
      put itemArray ["title"] into pageTitle
      delete variable itemArray ["title"] 
      /*
      put itemArray ["date"] into someTicks
      put itemArray ["synposis"] into pageSynposis
      put itemArray ["slug"] into pageSlug
      */
      put itemArray into sitemapTitleArray [pageTitle]
   end repeat
   return sitemapTitleArray
end fedwiki_ConstructSiteMapTitleArray

function fedwiki_ConstructUrlArray someUrl
   set the itemdelimiter to "/"
   put item 1 to 3 of someUrl into urlStem
   put item 3 of someUrl into urlDomain
   
   put item 4 to -1 of someUrl into pathBit
   put the number of items of pathBit into maxNum
   if (maxNum mod 2) is not 0 then 
      put item -1 of pathBit into extraBit
      delete item -1 of pathBit
      return false -- it is not a Fedwiki url ?
   end if
   
   put maxNum/2 into maxLineUpNum
   repeat with lineUpNum = 1 to maxLineUpNum
      put 2*lineUpNum - 1 into itemNum
      put item itemNum of pathBit into viewOrDomain
      put item (itemNum + 1) of pathBit into pageSlug
      _stripEndHashFromSlug pageSlug
      
      if viewOrDomain = "view" then
         put urlDomain into someDomain
      else
         put viewOrDomain into someDomain
      end if
      put pageSlug into urlArray [lineUpNum]["pageSlug"]
      put someDomain into urlArray [lineUpNum]["someDomain"]
   end repeat
   return urlArray
end fedwiki_ConstructUrlArray


--> Fedwiki | PageArray | Construct
-
function fedwiki_ConstructOpenStreetMapDescription locationDescription, mapZoom, mapLat, mapLong
   -- put "[[Mouans-Sartoux]], PACA, France - [http://www.openstreetmap.org/node/344280980#map=19/43.61935/6.97254 openstreetmap]" into mapText
   put "[[" & item 1 of locationDescription & "]]" into item 1 of locationDescription
   put fedwiki_ConstructOpenStreetMapLink (mapLat, mapLong, mapZoom, locationDescription) into mapDescription
   return mapDescription
end fedwiki_ConstructOpenStreetMapDescription

function fedwiki_ConstructOpenStreetMapLink mapLat, mapLong, pMapZoom, pLocationDescription
   put fedwiki_ConstructOpenStreetMapURL (mapLat, mapLong, pMapZoom) into openstreetmapURL
   put "- [" & openstreetmapURL && "openstreetmap]" into mapDescription
   if pLocationDescription is not empty then
      put pLocationDescription & space before mapDescription
   end if
   return mapDescription
end fedwiki_ConstructOpenStreetMapLink

function fedwiki_ConstructOpenStreetMapURL mapLat, mapLong, pMapZoom
   if pMapZoom is empty then put 15 into pMapZoom
   put "http://www.openstreetmap.org/#map=" & pMapZoom & "/" & mapLat & "/" & mapLong into openStreetMapURL
   return openStreetMapURL
end fedwiki_ConstructOpenStreetMapURL

function fedwiki_ConstructCodePageArray pageTitle, someCode, pSomeText, pSourceArray
   put pageTitle into pageArray ["title"]
   if pSomeText is not empty then pageArray_AddText pageArray, pSomeText
   pageArray_AddCode pageArray, someCode
   put pageArray_ConstructJournal (pageTitle, pSourceArray) into pageArray ["journal"] 
   return pageArray
end fedwiki_ConstructCodePageArray

function fedwiki_JsonEncode someText
   put utf8_Encode (someText) into utf8Text
   replace "&quot;" with quote in utf8Text
   return utf8Text
end fedwiki_JsonEncode

function youtube_ConstructWatchUrl videoID
   put "https://www.youtube.com/watch?v=" & videoID into youtubeURL
   return youtubeURL
end youtube_ConstructWatchUrl

function vimeo_ConstructWatchUrl videoID
   put "https://vimeo.com/" & videoID into vimeoURL
   return vimeoURL
end vimeo_ConstructWatchUrl


--> Private
-
private command _stripEndHashFromSlug @pageSlug
   set the itemdelimiter to "#"
   put item 1 of pageSlug into pageSlug
end _stripEndHashFromSlug


--> Deps
-
command date_ConvertMilliseconds @someMilliseconds
   put someMilliseconds/1000 into someMilliseconds
   convert someMilliseconds from seconds to long date
   delete item 1 of someMilliseconds
end date_ConvertMilliseconds

function google_ConstructCreativeCommonsSearchUrl searchWords
   put urlencode (searchWords) into searchBit
   get merge ("https://www.google.com/search?as_st=y&tbm=isch&as_q=[[searchBit]]&as_epq=&as_oq=&as_eq=&cr=&as_sitesearch=&safe=images&tbs=sur:fmc&gws_rd=ssl")
   return it
end google_ConstructCreativeCommonsSearchUrl

function utf8_Encode someText
   put unidecode(uniencode (someText),"UTF8") into encodedText
   return encodedText
end utf8_Encode

command utf8_Decode @someUTF8
   put uniencode (someUTF8,"UTF8") into someU16
   put unidecode (someU16, "ANSI") into someUTF8
end utf8_Decode

function json_FromArray pArray, pForceRootType, pPretty
   repeat for each key tKey in pArray
      if pArray[tKey] is an array then
         put "}"&json_FromArray(pArray[tKey]) into pArray[tKey]
      end if
   end repeat
   return(mergJSONEncode("pArray",pForceRootType,pPretty))
end json_FromArray

function json_ToArray pJSON
   if pJSON is empty then return false
   try -- as otherwise an error with non-json causes script to exit
      local tArray,tKeys
      if pJSON is empty then return empty
      repeat for each line tKey in mergJSONDecode(pJSON,"tArray")
         put json_ToArray(tArray[tKey]) into tArray[tKey]
      end repeat
      return tArray
   catch e
      return empty
   end try
end json_ToArray

command xml_BlankError @xmlBit
   if item 1 of xmlBit = "xmlerr" then put empty into xmlBit
end xml_BlankError

function html_ConstructImageDiv imageURL
   -- see fedwiki_ConstructImageHtml (imageURL, pCaption, pCaptionLinkURL, pLinkToImage)
   put merge ("<div align=center><img src='[[imageURL]]' width=100%></div>") into someHTML
   return someHTML
end html_ConstructImageDiv

command html_TopAndTailParagraphTags @someHTML
   get token 1 to 3 of someHTML
   replace space with empty in it
   if it is not "<p>" then return false
   
   delete token 1 to 3 of someHTML
   get token -3 to -1 of someHTML
   replace space with empty in it
   if it is "</p>" then
      delete token -3 to -1 of someHTML
   end if
   return true
end html_TopAndTailParagraphTags

function html_FetchTidy someURL
   put "curl -s" && someURL && "| tidy -asxhtml --quiet yes --tidy-mark no --show-warnings false --show-errors 0" into someShell
   put shell (someShell) into someXhtml   
   return someXhtml
end html_FetchTidy

function html_ConstructRefLink someText, someLink, pTarget
   if someLink is empty then return someText
   replace quote with "&quot;" in someLink
   put "<a href=" & quote & someLink & quote  into someLink
   if pTarget is not empty then
      -- "_blank" -- for opening in a new window
      put space & "target=" &quote& pTarget &quote after someLink
   end if
   put ">" & someText & "</a>" after someLink
   return someLink
end html_ConstructRefLink

function html_ExtractTLD someURL, pLastTwo
   set the itemdelimiter to slash
   put item 3 of someURL into someTLD
   if pLastTwo is not true then return someTLD
   
   set the itemdelimiter to "."
   put item -2 to -1 of someTLD into tldBit
   return tldBit
end html_ExtractTLD

command text_StripReg @wikiText, someReg, pReplaceText
   local refStart, refEnd
   put 0 into indexNum
   repeat
      get matchchunk (wikiText, someReg, sNum, eNum)
      if sNum is not a number then
         put the result into testResult
         -- breakpoint
         exit repeat -- regExp bug???
      end if
      
      if it is true then
         -- this bit not needed (remove for speed)
         -- put char refStart to refEnd of wikiText into someTest
         put sNum into stripResultArray [indexNum]["sNum"]
         put eNum into stripResultArray [indexNum]["eNum"]
         add 1 to indexNum
         --
         -- delete char sNum to eNum of wikiText
         put pReplaceText into char sNum to eNum of wikiText
      else
         exit repeat
      end if
   end repeat
   return stripResultArray
end text_StripReg

function text_SplitIntoParagraphs someText
   replace ". " with ("." & CR) in someText 
   -- now could combine lines that are too short
   return someText
end text_SplitIntoParagraphs

function text_StripAllTags someXml
   put  "(<(.|\n)+?>)" into someReg	# 
   return word 1 to -1 of replacetext(someXml, someReg, empty)
end text_StripAllTags

function text_InitialCaps someText
   repeat with wordNum = 1 to the number of words of someText
      put tolower(word wordNum of someText) into someWord
      put toupper(char 1 of someWord ) into char 1 of someWord
      put someWord into word wordNum of someText
   end repeat
   return someText
end text_InitialCaps

function line_ListUnique someIndex, pStripIndex
   -- split someIndex by CR as set -- uses new array syntax
   
   split someIndex by CR and tab
   if pStripIndex is not empty then
      -- split pStripIndex by CR as set
      -- difference someIndex with pStripIndex
      split pStripIndex by CR and tab
      repeat for each key someKey in pStripIndex
         delete variable someIndex [someKey]
      end repeat
   end if
   --
   put keys (someIndex) into uniqueIndex
   return uniqueIndex
end line_ListUnique

command line_DeleteIndex @someIndex, pStripIndex
   /*
   split someIndex by CR as set
   split pStripIndex by CR as set
   difference someIndex with pStripIndex
   put keys (someIndex) into uniqueIndex
   return uniqueIndex
   */
   
   repeat for each line someLine in pStripIndex
      line_Delete someLine, someIndex
      if lineNum = 0 then
         put lineNum & comma after deletedLines
      end if
   end repeat
   delete char -1 of deletedLines
   return deletedLines
end line_DeleteIndex

command line_Add someLines, @someIndex
   repeat for each line someLine in someLines
      if someLine is empty then next repeat
      set the wholematches to true
      put lineoffset(someLine, someIndex) into lineNum
      if lineNum is 0 then
         put the number of lines of someIndex into maxLine
         put maxLine + 1 into lineNum
         put someLine into line lineNum of someIndex
      else
         put lineNum & comma after lineNums
      end if
   end repeat
   delete char -1 of lineNums
   return lineNums
end line_Add

command line_Delete someLine, @someIndex
   set the wholematches to true
   put lineoffset (someLine, someIndex) into lineNum
   delete line lineNum of someIndex
   return lineNum
end line_Delete

function line_GetCommon index1, index2
   -- could use arrays
   set the wholematches to true
   put empty into commonIndex
   repeat for each line someLine in index1
      if someLine is among the lines of index2 then
         put someLine & return after commonIndex
      end if
   end repeat
   delete last char of commonIndex
   return commonIndex
end line_GetCommon

function url_ListTopDomains domainNames
   put url_ConstructTopLevelDomainArray (domainNames) into domainNameArray
   put keys (domainNameArray) into topDomainNames
   url_SortDomainIndex topDomainNames
   return topDomainNames
end url_ListTopDomains

command line_SetUnique @someIndex, pCaseSensitive
   if pCaseSensitive is false then
      split someIndex by CR and tab
      put the keys of someIndex into uniqueIndex
      put word 1 to -1 of uniqueIndex into someIndex
   else
      repeat for each line someLine in someIndex
         put word 1 to -1 of someLine into someLine
         if someLine is empty then next repeat
         put empty into indexArray [someLine]
      end repeat
      put keys (indexArray) into someIndex
   end if
end line_SetUnique

function url_ListTopDomains domainNames
   put url_ConstructTopLevelDomainArray (domainNames) into domainNameArray
   put keys (domainNameArray) into topDomainNames
   url_SortDomainIndex topDomainNames
   return topDomainNames
end url_ListTopDomains

function url_ConstructTopLevelDomainArray domainNames
   /*
   gets a reverse-polish style array of domain names
   items keys with ["domain name"] are the domainname
   remove from lists to get subdomains
   */
   
   set the itemdelimiter to "."
   repeat for each line domainName in domainNames
      set the cursor to busy
      url_DeconstructTopDomain domainName, topDomainName, subDomainBit
      
      -- let's reverse the order
      put 1 into keyNum
      put true into isIpAdress
      repeat with itemNum = the number of items of subDomainBit down to 1
         put item itemNum of subDomainBit into domainBit
         if domainBit is not a number then
            put false into isIpAdress
         end if
         put domainBit into keyArray [keyNum]
         add 1 to keyNum
      end repeat
      
      if isIpAdress is true then
         put empty into domainNameArray [topDomainName]
         next repeat
      end if
      
      if keyArray is an array then
         put domainName into domainNameArray [topDomainName]["subdomain"][keyArray]["domain name"]
      else
         put domainName into domainNameArray [topDomainName]["domain"]["domain name"]
      end if
      delete variable keyArray
   end repeat
   return domainNameArray
end url_ConstructTopLevelDomainArray

command url_DeconstructTopDomain domainString, @topDomainName, @subDomainBit
   -- a quick hack
   -- could check it is a url first
   
   set the itemdelimiter to ":"
   put item 1 of domainString into domainName
   -- put item 2 of domainString into somePort
   
   set the itemdelimiter to "."
   switch
      case item -2 to -1 of domainName = "co.uk"
         put item -3 to -1 of domainName into topDomainName
         put item 1 to -4 of domainName into subDomainBit
         break
      case the number of items of domainName = 2
         put domainName into topDomainName
         put empty into subDomainBit
         break
      default
         put item -2 to -1 of domainName into topDomainName
         put item 1 to -3 of domainName into subDomainBit
   end switch
end url_DeconstructTopDomain

command url_CheckDomainIndex @domainNames
   -- could have option to test actual domains
   -- quick check to remove pages without "."
   repeat for each line domainName in domainNames
      if domainName contains "." is true then
         put domainName & CR after goodDomains
      end if
   end repeat
   delete char -1 of goodDomains
   put goodDomains into domainNames
   return true
end url_CheckDomainIndex

command url_SortDomainIndex @domainNames
   set the itemdelimiter to "."
   sort domainNames by item -2 of each & item -3 of each & item -4 of each & item -5 of each
   line_DeleteTail domainNames
   return domainNames
end url_SortDomainIndex

command url_FilterDomainIndex @domainIndex, topDomain
   if topDomain is empty then return empty
   put "*." & topDomain into someFilter
   set the wholematches to true
   put topDomain is among the lines of domainIndex into topThere
   filter domainIndex with someFilter
   if topThere then
      put topDomain & CR before domainIndex
   end if
   return someFilter
end url_FilterDomainIndex

command line_DeleteTail @someIndex
   repeat the number of lines of someIndex
      get word 1 to -1 of line -1 of someIndex
      if it is empty then
         delete line -1 of someIndex
      end if
   end repeat
end line_DeleteTail

command url_Deconstruct someUrl, @someProtocol, @urlDomain, @urlPath, @shortName, @fileExtension, @uName, @pWord
   /*
   -- from http://regexlib.com/REDetails.aspx?regexp_id=628
   -- put "(?:(?<protocol>http(?:s?)|ftp)(?:\:\/\/)) (?:(?<usrpwd>\w+\:\w+)(?:\@))? (?<domain>[^/\r\n\:]+)? (?<port>\:\d+)? (?<path>(?:\/.*)*\/)? (?<filename>.*?\.(?<ext>\w{2,4}))? (?<qrystr>\??(?:\w+\=[^\#]+)(?:\&?\w+\=\w+)*)* (?<bkmrk>\#.*)?" into someReg
   */
   
   set the itemdelimiter to ":"
   put item 1 of someUrl into someProtocol
   if someProtocol is among the items of "file:binFile:ftp:http:https" then
      put someUrl into someFile
      delete item 1 of someFile
      if char 1 to 2 of someFile = "//" then delete char 1 to 2 of someFile
      
      -- just in case it has a ? param at the end
      -- strip it for now
      set the itemdelimiter to "?"
      put item 1 of someFile into someFile
      set the itemdelimiter to ":"
      
      get offset("@", someFile)
      if it = 0 then
         put empty into uName
         put empty into pWord
      else
         put char 1 to (it - 1) of someFile into authBit
         repeat while char 1 of authBit is "/"
            delete char 1 of authBit
         end repeat
         if the number of items of authBit = 2 then
            put item 1 of authBit into uName
            put item 2 of authBit into pWord
            delete char 1 to it of someFile
         else
            -- "@" must be in url ignore
            put empty into uName
            put empty into pWord
         end if
      end if
      file_Deconstruct someFile, someRoot, shortName, fileExtension
      
      set the itemdelimiter to "/"
      put item 1 of someRoot into UrlDomain
      put item 2 to -1 of someRoot into urlPath
      return true
   else
      put empty into someProtocol
      put empty into UrlDomain
      put empty into urlPath
      put empty into shortName
      put empty into fileExtension
      put empty into uName
      put empty into pWord
      return false
   end if
end url_Deconstruct

command file_Deconstruct someFile, @someRoot, @shortName, @fileExtension
   -- was "deconstruct_File"
   -- should turn someRoot into someFolder and add "/" to end
   
   if someFile is empty then
      put the effective filename of this stack into someFile
   end if
   put someFile into someRoot
   put the itemdelimiter into originalDelim
   
   set the itemdelimiter to "/"
   put last item of someFile into shortName
   delete last item of someRoot
   
   if shortName contains "." then
      set the itemdelimiter to "."
      put last item of shortName into fileExtension
      delete last item of shortName
   else
      put empty into fileExtension
   end if
   set the itemdelimiter to originalDelim
end file_Deconstruct

function kwote someText, pQuoteChar
   if pQuoteChar is empty then put quote into pQuoteChar
   return pQuoteChar & someText & pQuoteChar
end kwote

